# Algorithm Discovery With LLMs: Evolutionary Search Meets Reinforcement Learning

![Method Image](./data/readme/method-fig.png)

[![Paper](https://img.shields.io/badge/Paper-arXiv%20preprint-b31b1b.svg)](https://arxiv.org/abs/2504.05108)
[![License](https://img.shields.io/github/license/CLAIRE-Labo/EvoTune)](./LICENSE)

Official repository for the paper:

> **Algorithm Discovery With LLMs: Evolutionary Search Meets Reinforcement Learning**  
> Anja Surina, Amin Mansouri, Lars Quaedvlieg, Amal Seddas, Maryna Viazovska, Emmanuel Abbe, Caglar Gulcehre

### Citation
```bibtex
@article{surina2025algorithm,
  title={Algorithm Discovery With LLMs: Evolutionary Search Meets Reinforcement Learning},
  author={Surina, Anja and Mansouri, Amin and Quaedvlieg, Lars and Seddas, Amal and Viazovska, Maryna and Abbe, Emmanuel and Gulcehre, Caglar},
  journal={arXiv preprint arXiv:2504.05108},
  year={2025}
}
```

---

## ðŸ§  Overview

**EvoTune** is a framework for discovering new algorithms by combining:

1. ðŸ§¬ Evolutionary search over LLM-generated Python programs, and
2. ðŸ† Reinforcement Learning to fine-tune the LLM based on relative program performances.

We show that this synergy improves both the performance and uniqueness of solutions across classic combinatorial problems, including:
- âœ… Bin Packing
- âœ… Traveling Salesman Problem (TSP)
- âœ… FlatPack Problem

---

## ðŸ“¦ Repo Structure

The core codebase lives under ```src/``` and is organized as follows:

```plaintext
projects/
â”œâ”€â”€ evotune/
â”‚   â”œâ”€â”€ configs/                  # Hydra-based config system
â”‚   â”‚   â”œâ”€â”€ accelerate_config/    # Accelerate (multi-GPU) configs
â”‚   â”‚   â”œâ”€â”€ cluster/              # SLURM / cluster overrides
â”‚   â”‚   â”œâ”€â”€ model/                # Model-specific settings
â”‚   â”‚   â”œâ”€â”€ sweep/                # Sweep configuration files
â”‚   â”‚   â”œâ”€â”€ task/                 # Per-task configs (e.g., bin, tsp, etc.)
â”‚   â”‚   â”œâ”€â”€ train/                # Training configuration
â”‚   â”‚   â””â”€â”€ config.yaml           # Default config
â”‚   â”œâ”€â”€ data/                     # Example datasets and readme assets
â”‚   â”œâ”€â”€ installation/             # Dockerfiles for various hardware (CUDA, TGI, vLLM)
â”‚   â”œâ”€â”€ scripts/                  # Example launch scripts for sweeps
â”‚   â”‚   â”œâ”€â”€ run_eval_sweep_example.sh
â”‚   â”‚   â””â”€â”€ run_train_sweep_example.sh
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ packing/             # Core EvoTune framework
â”‚       â”‚   â”œâ”€â”€ evaluate/        # Task-specific logic (registered via registry)
â”‚       â”‚   â”‚   â”œâ”€â”€ bin_packing/
â”‚       â”‚   â”‚   â”œâ”€â”€ flat_pack/
â”‚       â”‚   â”‚   â”œâ”€â”€ tsp/
â”‚       â”‚   â”‚   â”œâ”€â”€ __init__.py  # Auto-imports task modules
â”‚       â”‚   â”‚   â”œâ”€â”€ registry.py  # Central task registry
â”‚       â”‚   â”‚   â””â”€â”€ README.md    # How to add new tasks
â”‚       â”‚   â”œâ”€â”€ funsearch/       # Program database
â”‚       â”‚   â”œâ”€â”€ logging/         # Logging, statistics, and function tracking
â”‚       â”‚   â”œâ”€â”€ model/           # Prompting, LLM I/O, inference engine setup
â”‚       â”‚   â”œâ”€â”€ parallel/        # Multiprocessing producers & consumers
â”‚       â”‚   â”œâ”€â”€ train/           # DPO pipelines for fine-tuning LLMs
â”‚       â”‚   â””â”€â”€ utils/           # Seeding, function helpers, etc.
â”‚       â”œâ”€â”€ experiments/         # Scripts for specific experiments (train / eval)
â”‚       â””â”€â”€ plotting/            # Utilities for generating paper plots
â”œâ”€â”€ .pre-commit-config.yaml      # Code formatting & linting hooks
â”œâ”€â”€ pyproject.toml               # Build & dependency configuration
â”œâ”€â”€ LICENSE                      # License (MIT)
```

---

## âš™ï¸ Setup & Dependencies

To run EvoTune, you **must use a Docker container** due to dependencies on vLLM, JAX, and CUDA-incompatible multiprocessing. We provide optimized Dockerfiles under:

```plaintext
installation/
â”œâ”€â”€ docker-amd64-cuda-tgi/   # For x86_64 machines using TGI
â”œâ”€â”€ docker-amd64-cuda-vllm/  # For x86_64 machines using vLLM
â”œâ”€â”€ docker-arm64-cuda/       # For Apple Silicon (ARM64 + CUDA support)
```

Or, pull directly from Docker Hub:

```bash
# For AMD64
docker pull larsquaedvlieg/evotune:amd64-cuda

# For ARM64 (will be pushed to the hub soon)
docker pull larsquaedvlieg/evotune::arm64-cuda
```

> âœ… Most experiments were run using a **single A100 GPU (40GB)**. Lower memory GPUs (24GB or lower) may require reduced configurations.

---

## ðŸš€ How to Run the Code

You can run EvoTune either locally (inside Docker) or on a cluster.

### â–¶ï¸ Local Runs

The two main entry points are located in:

```plaintext
src/experiments/
â”œâ”€â”€ main.py   # For running training with evolution + finetuning
â”œâ”€â”€ eval.py   # For evaluating saved program banks
```

### ðŸ“¡ Cluster / Sweep Runs

We provide example sweep scripts in the ```scripts/``` folder:

```plaintext
scripts/
â”œâ”€â”€ run_eval_sweep_example.sh
â”œâ”€â”€ run_train_sweep_example.sh
```

These are designed to be used with job schedulers like SLURM or RunAI. To use them:

1. Fill in the ```# TODO``` block in each script with your cluster submission logic.
2. Configure the sweep/grid settings in the appropriate ```configs/sweep/``` and ```configs/cluster/``` YAML files.
3. Launch your sweep using the modified script.

> You can also run hyperparameter or task sweeps locally by adapting these scripts â€” just remove the SLURM logic.

---

## ðŸ§± Adding a New Task

To add your own task:

ðŸ‘‰ Navigate to:

```src/packing/evaluate/README.md```

Youâ€™ll find clear instructions for implementing and registering:

- ```generate_input```
- ```evaluate_func```
- ```get_initial_func```
- ```system_prompt``` / ```append_prompt```

The registry-based design ensures zero boilerplate in the main training loop.

---